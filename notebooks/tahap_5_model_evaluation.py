# -*- coding: utf-8 -*-
"""Tahap 5 Model Evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YrDwKo_OBiMy--Lshap1UyeUGgrMvbJn

# **Tahap 5 – Model Evaluation**

---

## TF-IDF
"""

import pandas as pd

# Baca hasil evaluasi
eval_path = "/content/drive/MyDrive/Penalaran Komputer/UAS/Data/eval/retrieval_metrics.csv"
df = pd.read_csv(eval_path)

# Hitung rata-rata metrik
precision_avg = df["precision"].mean() * 100
recall_avg = df["recall"].mean() * 100
f1_avg = df["f1_score"].mean() * 100
accuracy_avg = df["accuracy"].mean() * 100

# Format laporan
print("📈 Hasil Evaluasi Retrieval TF-IDF")
print("=" * 60)
print()
print("🔸 Precision")
print(f"   ├─ 🎯 Rata-rata : {precision_avg:.2f}%")
print("🔸 Recall")
print(f"   ├─ 🔁 Rata-rata : {recall_avg:.2f}%")
print("🔸 F1-Score")
print(f"   └─ 🧠 Rata-rata : {f1_avg:.2f}%")
print("🔸 Accuracy")
print(f"   └─ ✅ Rata-rata : {accuracy_avg:.2f}%")

"""## BERT"""

!pip install transformers sentence-transformers

from transformers import AutoTokenizer, AutoModel
import torch
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import json

# Load IndoBERT pretrained
model_name = "indobenchmark/indobert-base-p1"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

# Fungsi untuk mendapatkan embedding
def bert_embed(texts):
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt", max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling
    return embeddings.numpy()

df = pd.read_csv("/content/drive/MyDrive/Penalaran Komputer/UAS/Data/processed/cases.csv")
df["text_full"] = df["text_full"].fillna("")

# Bagi jadi potongan agar tidak over-memori
all_vectors = []
batch_size = 16

for i in range(0, len(df), batch_size):
    batch = df["text_full"].iloc[i:i+batch_size].tolist()
    vec = bert_embed(batch)
    all_vectors.extend(vec)

import numpy as np
case_vectors = np.array(all_vectors)

def retrieve_bert(query: str, k: int = 5):
    query_vec = bert_embed([query])
    similarity = cosine_similarity(query_vec, case_vectors)[0]
    top_k_idx = similarity.argsort()[-k:][::-1]
    top_k_case_ids = df.iloc[top_k_idx]["case_id"].tolist()
    return top_k_case_ids

with open("/content/drive/MyDrive/Penalaran Komputer/UAS/Data/eval/queries.json", "r") as f:
    queries = json.load(f)

with open("/content/drive/MyDrive/Penalaran Komputer/UAS/Data/eval/ground_truth.json", "r") as f:
    ground_truth = json.load(f)

results = []

for q in queries:
    qid = q["query_id"]
    query_text = q["query_text"]
    top_k = retrieve_bert(query_text, k=5)

    gt = set(map(int, ground_truth.get(qid, [])))
    retrieved = set(top_k)

    tp = len(gt & retrieved)
    fp = len(retrieved - gt)
    fn = len(gt - retrieved)

    precision = tp / (tp + fp) if (tp + fp) else 0
    recall = tp / (tp + fn) if (tp + fn) else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0
    accuracy = tp / 5

    results.append({
        "query_id": qid,
        "accuracy": round(accuracy, 4),
        "precision": round(precision, 4),
        "recall": round(recall, 4),
        "f1_score": round(f1, 4),
        "top_k_case_ids": list(top_k),
        "ground_truth": list(gt)
    })

# Simpan hasil evaluasi BERT
df_result = pd.DataFrame(results)
output_path = "/content/drive/MyDrive/Penalaran Komputer/UAS/Data/eval/retrieval_metrics_bert.csv"
df_result.to_csv(output_path, index=False)
print(f"✅ Evaluasi IndoBERT disimpan di: {output_path}")

import pandas as pd

# Baca hasil evaluasi
eval_path = "/content/drive/MyDrive/Penalaran Komputer/UAS/Data/eval/retrieval_metrics_bert.csv"
df = pd.read_csv(eval_path)

# Hitung rata-rata metrik
precision_avg = df["precision"].mean() * 100
recall_avg = df["recall"].mean() * 100
f1_avg = df["f1_score"].mean() * 100
accuracy_avg = df["accuracy"].mean() * 100

# Format laporan
print("📈 Hasil Evaluasi Retrieval TF-IDF")
print("=" * 60)
print()
print("🔸 Precision")
print(f"   ├─ 🎯 Rata-rata : {precision_avg:.2f}%")
print("🔸 Recall")
print(f"   ├─ 🔁 Rata-rata : {recall_avg:.2f}%")
print("🔸 F1-Score")
print(f"   └─ 🧠 Rata-rata : {f1_avg:.2f}%")
print("🔸 Accuracy")
print(f"   └─ ✅ Rata-rata : {accuracy_avg:.2f}%")

"""## TF-IDF vs BERT"""

import pandas as pd

# Load hasil evaluasi TF-IDF dan BERT
tfidf_path = "/content/drive/MyDrive/Penalaran Komputer/UAS/Data/eval/retrieval_metrics.csv"
bert_path = "/content/drive/MyDrive/Penalaran Komputer/UAS/Data/eval/retrieval_metrics_bert.csv"

df_tfidf = pd.read_csv(tfidf_path)
df_bert = pd.read_csv(bert_path)

def summarize(df):
    return {
        "Precision": df["precision"].mean() * 100,
        "Recall": df["recall"].mean() * 100,
        "F1-Score": df["f1_score"].mean() * 100,
        "Accuracy": df["accuracy"].mean() * 100
    }

metrics_tfidf = summarize(df_tfidf)
metrics_bert = summarize(df_bert)

# 🖨️ Format output mirip ROUGE
def print_eval(name, metrics):
    print(f"🔸 {name}")
    print(f"   ├─ 🎯 Precision : {metrics['Precision']:.2f}%")
    print(f"   ├─ 🔁 Recall    : {metrics['Recall']:.2f}%")
    print(f"   ├─ 🧠 F1-Score  : {metrics['F1-Score']:.2f}%")
    print(f"   └─ ✅ Accuracy  : {metrics['Accuracy']:.2f}%")
    print()

# Cetak laporan
print("📈 Hasil Evaluasi Model Retrieval – Perbandingan")
print("=" * 65)
print_eval("TF-IDF + Cosine", metrics_tfidf)
print_eval("BERT Embedding", metrics_bert)

"""## Plot Bar Chart Performa Model"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load hasil evaluasi
path_tfidf = "/content/drive/MyDrive/Penalaran Komputer/UAS/Data/eval/retrieval_metrics.csv"
path_bert = "/content/drive/MyDrive/Penalaran Komputer/UAS/Data/eval/retrieval_metrics_bert.csv"

df_tfidf = pd.read_csv(path_tfidf)
df_bert = pd.read_csv(path_bert)

# Ambil rata-rata metrik
tfidf_scores = {
    "Model": "TF-IDF",
    "Accuracy": df_tfidf["accuracy"].mean() * 100,
    "Precision": df_tfidf["precision"].mean() * 100,
    "Recall": df_tfidf["recall"].mean() * 100,
    "F1-Score": df_tfidf["f1_score"].mean() * 100
}

bert_scores = {
    "Model": "BERT",
    "Accuracy": df_bert["accuracy"].mean() * 100,
    "Precision": df_bert["precision"].mean() * 100,
    "Recall": df_bert["recall"].mean() * 100,
    "F1-Score": df_bert["f1_score"].mean() * 100
}

# Gabung ke DataFrame
df_plot = pd.DataFrame([tfidf_scores, bert_scores])
df_plot = df_plot.melt(id_vars="Model", var_name="Metric", value_name="Score")

plt.figure(figsize=(10, 6))
sns.barplot(data=df_plot, x="Metric", y="Score", hue="Model", palette="Set2")
plt.title("📊 Perbandingan Performa Model Retrieval (TF-IDF vs BERT)", fontsize=14)
plt.ylabel("Score (%)")
plt.ylim(0, 100)
plt.grid(True, axis='y', linestyle='--', alpha=0.7)
plt.legend(title="Model")
plt.tight_layout()
plt.show()

plt.savefig("/content/drive/MyDrive/Penalaran Komputer/UAS/Data/eval/performance_comparison.png")